{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3c874e-9130-4c4a-b46a-bd5d4aa53a67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as ss\n",
    "\n",
    "import matplotlib as mp\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import utils as ut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a107a912-4c1c-4a3a-bced-1ab02b5cc48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.expanduser('~/github/congrat'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcbe90d-da98-41c8-8af3-e088901cb075",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.seed_everything(2969591811)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d7e81a-d6e6-48bc-818f-0cb7788b665f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3f7911-d1cc-4113-9af0-0aec8cfff728",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'data/evals/'\n",
    "split = 'test'\n",
    "\n",
    "undirected_files = [\n",
    "    'causal-base',\n",
    "    'causal-sim10',\n",
    "\n",
    "    'masked-base',\n",
    "    'masked-sim10',\n",
    "]\n",
    "\n",
    "directed_files = [\n",
    "    'causal-base',\n",
    "    'masked-base',\n",
    "]\n",
    "\n",
    "datasets = {\n",
    "    'pubmed': {\n",
    "        'name': 'Pubmed (Undirected)',\n",
    "        'files': undirected_files,\n",
    "    },\n",
    "    \n",
    "    'trex': {\n",
    "        'name': 'TRex (Undirected)',\n",
    "        'files': undirected_files,\n",
    "    },\n",
    "    \n",
    "    'twitter-small': {\n",
    "        'name': 'Twitter (Undirected)',\n",
    "        'files': undirected_files,\n",
    "    },\n",
    "    \n",
    "    'pubmed-directed': {\n",
    "        'name': 'Pubmed (Directed)',\n",
    "        'files': directed_files,\n",
    "    },\n",
    "    \n",
    "    'trex-directed': {\n",
    "        'name': 'TRex (Directed)',\n",
    "        'files': directed_files,\n",
    "    },\n",
    "    \n",
    "    'twitter-small-directed': {\n",
    "        'name': 'Twitter (Directed)',\n",
    "        'files': directed_files,\n",
    "    },\n",
    "}\n",
    "\n",
    "dataset_names = {k : v['name'] for k, v in datasets.items()}\n",
    "\n",
    "evals = {}\n",
    "for dataset, obj in datasets.items():\n",
    "    evals[dataset] = {}\n",
    "    for file in obj['files']:\n",
    "        with open(os.path.join(prefix, f'{dataset}-{split}-{file}.json'), 'rt') as f:\n",
    "            evals[dataset][file] = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcb96ee-0a08-4f06-9e2e-fde8d5b1c8b1",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06b0f2b-4c55-46fc-a1eb-a6c0d5d6fec0",
   "metadata": {},
   "source": [
    "## Top-k accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b51e31-835f-437d-aa2b-eeb8566917b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "exact_topk = pd.concat([\n",
    "    pd.DataFrame(evals[dataset][file]['eval_topk_accuracy']['exact_point']).assign(dataset=dataset, model=file)\n",
    "    for dataset in datasets for file in datasets[dataset]['files']\n",
    "], axis=0).set_index(['dataset', 'model', 'k']).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b654a71d-00d8-4f30-8e87-cd96d6ede7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "runs_topk = pd.concat([\n",
    "    pd.DataFrame(evals[dataset][file]['eval_topk_accuracy']['resample']).assign(dataset=dataset, model=file)\n",
    "    for dataset in datasets for file in datasets[dataset]['files']\n",
    "], axis=0).set_index(['dataset', 'model', 'run', 'k']).sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9a8619-3761-45f0-b2b3-c5ce702a52db",
   "metadata": {},
   "source": [
    "## Within-node similarity pre-post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df924624-e3d6-4c39-93ac-0ca9d457656a",
   "metadata": {},
   "outputs": [],
   "source": [
    "exact_node_recovery = pd.concat([\n",
    "    pd.Series(evals[dataset][file]['eval_within_node_dist_pre_post']['exact_point']).rename((dataset, file))\n",
    "    for dataset in datasets for file in datasets[dataset]['files']\n",
    "], axis=1).T\n",
    "\n",
    "exact_node_recovery.index.names = ['dataset', 'model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf8dc2d-1423-40a2-a7df-1c2938935fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "runs_node_recovery = pd.concat([\n",
    "    pd.DataFrame(evals[dataset][file]['eval_within_node_dist_pre_post']['resample']).assign(dataset=dataset, model=file)\n",
    "    for dataset in datasets for file in datasets[dataset]['files']\n",
    "], axis=0).set_index(['dataset', 'model', 'run'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f032c77-a3cc-45fd-93dc-513e4b97d48e",
   "metadata": {},
   "source": [
    "## Correlation of distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14532880-8c83-486b-9fdb-fa368829e1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "runs_dist_corr = pd.concat([\n",
    "    pd.DataFrame(evals[dataset][file]['eval_emb_dist_coupling']['resample']).assign(dataset=dataset, model=file)\n",
    "    for dataset in datasets for file in datasets[dataset]['files']\n",
    "], axis=0).set_index(['dataset', 'model', 'run'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e905e0e-72f9-4e64-8ad0-34dab087aa2e",
   "metadata": {},
   "source": [
    "## Embedding distances vs graph distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b207c03-5e0f-43eb-b85c-528da89a4dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "runs_emb_vs_graph = pd.concat([\n",
    "    pd.DataFrame(evals[dataset][file]['eval_emb_dist_vs_graph_dist']['resample']).assign(dataset=dataset, model=file)\n",
    "    for dataset in datasets for file in datasets[dataset]['files']\n",
    "], axis=0).set_index(['dataset', 'model', 'run'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953bdb06-0a62-41da-80c9-9f4602fd28e2",
   "metadata": {},
   "source": [
    "# Top-k accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6f0ca6-b6b0-48b3-bda2-93ede0e243bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "topk_stats = []\n",
    "\n",
    "for dataset in datasets:\n",
    "    ## Masked\n",
    "    cols = [f for f in datasets[dataset]['files'] if f.startswith('masked')]\n",
    "    tmpmb = exact_topk.loc[dataset, ...].unstack(0).loc[:, ('comp_acc', 'masked-base')].rename('baseline')\n",
    "    \n",
    "    tmpm = exact_topk.loc[dataset, ...].unstack(0).loc[:, pd.IndexSlice['trained_acc', cols]]\n",
    "    tmpm.columns = tmpm.columns.droplevel(0)\n",
    "    tmpm.columns = [c.replace('masked-', '') if c.startswith('masked-') else c for c in tmpm.columns]\n",
    "    tmpm = pd.concat([tmpm, tmpmb], axis=1)\n",
    "    tmpm = tmpm.unstack(0).reset_index().rename({'level_0': 'model', 0: 'acc'}, axis=1)\n",
    "    tmpm['lmtype'] = 'masked'\n",
    "    \n",
    "    ## Causal\n",
    "    cols = [f for f in datasets[dataset]['files'] if f.startswith('causal')]\n",
    "    tmpcb = exact_topk.loc[dataset, ...].unstack(0).loc[:, ('comp_acc', 'causal-base')].rename('baseline')\n",
    "    \n",
    "    tmpc = exact_topk.loc[dataset, ...].unstack(0).loc[:, pd.IndexSlice['trained_acc', cols]]\n",
    "    tmpc.columns = tmpc.columns.droplevel(0)\n",
    "    tmpc.columns = [c.replace('causal-', '') if c.startswith('causal-') else c for c in tmpc.columns]\n",
    "    tmpc = pd.concat([tmpc, tmpcb], axis=1)\n",
    "    tmpc = tmpc.unstack(0).reset_index().rename({'level_0': 'model', 0: 'acc'}, axis=1)\n",
    "    tmpc['lmtype'] = 'causal'\n",
    "\n",
    "    tmp = pd.concat([tmpm, tmpc], axis=0)\n",
    "    tmp['dataset'] = dataset\n",
    "    \n",
    "    topk_stats += [tmp]\n",
    "\n",
    "topk_stats = pd.concat(topk_stats, axis=0)\n",
    "\n",
    "topk_stats['directed'] = topk_stats['dataset'].apply(lambda s: 'directed' if s.endswith('-directed') else 'undirected')\n",
    "topk_stats['dataset'] = topk_stats['dataset'].str.replace('-directed', '')\n",
    "topk_stats['dataset'] = topk_stats['dataset'].map({\n",
    "    'pubmed': 'pubmed',\n",
    "    'trex': 'trex',\n",
    "    'twitter-small': 'twitter',\n",
    "})\n",
    "\n",
    "#topk_stats = topk_stats.set_index(['dataset', 'directed', 'lmtype', 'model', 'k']).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e9da79-4aa7-4c73-a0df-de5b003be445",
   "metadata": {},
   "outputs": [],
   "source": [
    "ncol = 2\n",
    "nrow = topk_stats['dataset'].nunique()\n",
    "\n",
    "fig = plt.figure(figsize=(5 * ncol, 5 * nrow), constrained_layout=True)\n",
    "fig.suptitle('Top-k Accuracy: Predicting Origin Node for Text')\n",
    "\n",
    "subfigs = fig.subfigures(nrows=nrow, ncols=1)#, sharex=True, sharey=True)\n",
    "for i, (subfig, dataset) in enumerate(zip(subfigs, topk_stats['dataset'].unique())):\n",
    "    tmp = topk_stats.loc[topk_stats['dataset'] == dataset, :].drop('dataset', axis=1)\n",
    "    tmpm = tmp.loc[tmp['lmtype'] == 'masked', :].drop('lmtype', axis=1)\n",
    "    tmpc = tmp.loc[tmp['lmtype'] == 'causal', :].drop('lmtype', axis=1)\n",
    "    \n",
    "    subfig.suptitle(dataset.title())\n",
    "    axes = subfig.subplots(nrows=1, ncols=ncol)\n",
    "    \n",
    "    ## Masked\n",
    "    bas = tmpm.loc[tmpm['model'] == 'baseline', ['directed', 'k', 'acc']].set_index(['directed', 'k']).unstack(0)\n",
    "    bas.columns = bas.columns.droplevel(0)\n",
    "    bas['directed'].plot(ax=axes[0], label='Directed Baseline')\n",
    "    bas['undirected'].plot(ax=axes[0], label='Undirected Baseline')\n",
    "    \n",
    "    bas = tmpm.loc[tmpm['model'] == 'base', ['directed', 'k', 'acc']].set_index(['directed', 'k']).unstack(0)\n",
    "    bas.columns = bas.columns.droplevel(0)\n",
    "    bas['directed'].plot(ax=axes[0], label=r'Directed, $\\alpha = 0$')\n",
    "    bas['undirected'].plot(ax=axes[0], label=r'Undirected, $\\alpha = 0$')\n",
    "\n",
    "    bas = tmpm.loc[tmpm['model'] == 'sim10', ['k', 'acc']].set_index('k').unstack(0)\n",
    "    bas.index = bas.index.droplevel()\n",
    "    bas.plot(ax=axes[0], label=r'Undirected, $\\alpha = 0.1$')\n",
    "        \n",
    "    ## Causal\n",
    "    bas = tmpc.loc[tmpc['model'] == 'baseline', ['directed', 'k', 'acc']].set_index(['directed', 'k']).unstack(0)\n",
    "    bas.columns = bas.columns.droplevel(0)\n",
    "    bas['directed'].plot(ax=axes[1], label='Directed Baseline')\n",
    "    bas['undirected'].plot(ax=axes[1], label='Undirected Baseline')\n",
    "    \n",
    "    bas = tmpc.loc[tmpc['model'] == 'base', ['directed', 'k', 'acc']].set_index(['directed', 'k']).unstack(0)\n",
    "    bas.columns = bas.columns.droplevel(0)\n",
    "    bas['directed'].plot(ax=axes[1], label=r'Directed, $\\alpha = 0$')\n",
    "    bas['undirected'].plot(ax=axes[1], label=r'Undirected, $\\alpha = 0$')\n",
    "\n",
    "    bas = tmpc.loc[tmpc['model'] == 'sim10', ['k', 'acc']].set_index('k').unstack(0)\n",
    "    bas.index = bas.index.droplevel()\n",
    "    bas.plot(ax=axes[1], label=r'Undirected, $\\alpha = 0.1$')\n",
    "    \n",
    "    axes[0].set_title('Masked')\n",
    "    axes[1].set_title('Causal')\n",
    "    \n",
    "    axes[0].legend()\n",
    "    axes[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e7033a-0f22-4c2c-ad62-c8cfa04fa389",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = exact_topk.loc[pd.IndexSlice[:, :, [1, 5, 10]], :] \\\n",
    "    [['trained_acc', 'comp_acc']] \\\n",
    "    .unstack(1)\n",
    "\n",
    "cols = [c for c in tmp.columns if c[0] == 'trained_acc' or c[1] in ('causal-base', 'masked-base')]\n",
    "tmp = tmp.loc[:, cols]\n",
    "\n",
    "tmp.columns = [c[0] + '_' + c[1] for c in tmp.columns]\n",
    "tmp = tmp.rename({\n",
    "    'comp_acc_causal-base': 'trained_acc_causal-baseline',\n",
    "    'comp_acc_masked-base': 'trained_acc_masked-baseline',\n",
    "}, axis=1)\n",
    "tmp.columns = [c.replace('trained_acc_', '') if c.startswith('trained_acc_') else c for c in tmp.columns]\n",
    "tmp = tmp[sorted(tmp.columns)]\n",
    "\n",
    "tmp.columns = tmp.columns.str.split('-', 1, expand=True)\n",
    "tmp.columns = tmp.columns.set_levels(tmp.columns.levels[0].str.title(), level=0)\n",
    "tmp.columns = tmp.columns.set_levels(tmp.columns.levels[1].map({\n",
    "    'base': 'sim0',\n",
    "    'sim10': 'sim10',\n",
    "    'sim50': 'sim50',\n",
    "    'simexp': 'sim10_exp',\n",
    "    'simexptt': 'sim10_exptt',\n",
    "    'baseline': 'Baseline',\n",
    "}), level=1)\n",
    "tmp = tmp[sorted(tmp.columns)]\n",
    "\n",
    "tmp.index = tmp.index.set_levels(tmp.index.levels[0].map(dataset_names), level=0)\n",
    "\n",
    "tmp = tmp.stack(0).reorder_levels([0, 2, 1]).sort_index()\n",
    "\n",
    "tab = tmp.style \\\n",
    "    .format(precision=3) \\\n",
    "    .apply(ut.bold_largest_by_row, axis=1)\n",
    "\n",
    "display(tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2df2c2-9c6c-4cb5-962c-ed80b17e0b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tab.to_latex(\n",
    "        hrules = True,\n",
    "        column_format = 'lr|rrrrrr',\n",
    "        position = 'ht',\n",
    "        label = 'tab:topk_acc',\n",
    "        multicol_align = '|c',\n",
    "        position_float = 'centering',\n",
    "        environment = 'table',\n",
    "        convert_css = True,\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5603319f-6e00-4ae6-b3bb-d23d4e9aad9e",
   "metadata": {},
   "source": [
    "# Summarize other metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418eef8b-5263-4e87-ae4d-078cd14f3009",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = {\n",
    "    'Distance Coupling': runs_dist_corr.groupby(level=[0,1]).mean()[['trained_corr', 'comp_corr']] \\\n",
    "                         .rename({'trained_corr': 'Joint', 'comp_corr': 'Baseline'}, axis=1),\n",
    "\n",
    "    'Emb. vs Graph: Text': runs_emb_vs_graph.groupby(level=[0,1]).mean()[['trained_text_corr', 'comp_text_corr']] \\\n",
    "                       .rename({'trained_text_corr': 'Joint', 'comp_text_corr': 'Baseline'}, axis=1),\n",
    "}\n",
    "\n",
    "stats = pd.concat(stats.values(), keys=stats.keys(), axis=1).reset_index()\n",
    "\n",
    "stats['directed'] = stats['dataset'].apply(lambda s: 'Directed' if 'directed' in s else 'Undirected')\n",
    "stats['lmtype'] = stats['model'].apply(lambda s: s.split('-')[0].title())\n",
    "stats['model'] = stats['model'].apply(lambda s: s.split('-')[1])\n",
    "stats['model'] = stats['model'].map({'base': r'$\\alpha = 0.0$', 'sim10': r'$\\alpha = 0.1$'})\n",
    "stats['dataset'] = stats['dataset'].map({\n",
    "    'pubmed': 'Pubmed',\n",
    "    'trex': 'TRex',\n",
    "    'twitter-small': 'Twitter',\n",
    "    'pubmed-directed': 'Pubmed',\n",
    "    'trex-directed': 'TRex',\n",
    "    'twitter-small-directed': 'Twitter',    \n",
    "})\n",
    "\n",
    "stats = stats.set_index(['dataset', 'directed', 'lmtype', 'model']).sort_index(ascending=True)\n",
    "stats.index.names = ['Dataset', 'Directed', 'LM Type', 'Sim.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b563a36e-968f-4b69-9e6d-c738091d0a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tab = stats \\\n",
    "    .loc[:, ['Distance Coupling', 'Emb. vs Graph: Text']] \\\n",
    "    .style \\\n",
    "    .format(precision=3) \\\n",
    "    .apply(ut.bold_largest_by_metric, axis=1)\n",
    "\n",
    "with pd.option_context('display.html.use_mathjax', True):\n",
    "    display(tab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7681193f-ac25-480c-a40f-bfafe8c1e622",
   "metadata": {},
   "source": [
    "## LaTeX tables for paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fce8b4e-88b4-420f-94f4-3cb4a6b32b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stats \\\n",
    "    .loc[:, ['Distance Coupling', 'Emb. vs Graph: Text']] \\\n",
    "    .style \\\n",
    "    .format(precision=3) \\\n",
    "    .apply(ut.bold_largest_by_metric, axis=1) \\\n",
    "    .to_latex(\n",
    "        hrules = True,\n",
    "        column_format = 'lllr|rr|rr',\n",
    "        position = 'ht',\n",
    "        label = 'tab:cross-modality-results',\n",
    "        multicol_align = '|c',\n",
    "        position_float = 'centering',\n",
    "        environment = 'table*',\n",
    "        convert_css = True,\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf9a3fd-186c-47df-bfbe-513e7be43b14",
   "metadata": {},
   "source": [
    "# Hypothesis tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7709ca-40f8-42f5-8f62-d591b7084fc2",
   "metadata": {},
   "source": [
    "## Top-k accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43174b46-453e-4f0c-ab34-5cf14c6c712b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tmp = runs_topk.groupby(level=['dataset', 'model', 'k'])[['trained_acc', 'comp_acc', 'diff_acc']].describe().loc[:, pd.IndexSlice[:, 'mean']]\n",
    "tmp.columns = [c[0] for c in tmp.columns]\n",
    "\n",
    "tmp = tmp.rename({'trained_acc': 'trained_acc_resample', 'comp_acc': 'comp_acc_resample', 'diff_acc': 'diff_acc_resample'}, axis=1)\n",
    "tmp = tmp.merge(exact_topk, how='inner', left_index=True, right_index=True)\n",
    "\n",
    "assert tmp.shape[0] == exact_topk.shape[0]\n",
    "\n",
    "tmp['trained_acc_diff'] = tmp['trained_acc'] - tmp['trained_acc_resample']\n",
    "tmp['comp_acc_diff'] = tmp['comp_acc'] - tmp['comp_acc_resample']\n",
    "tmp['diff_acc_diff'] = tmp['diff_acc'] - tmp['diff_acc_resample']\n",
    "\n",
    "tmp[['trained_acc_diff', 'comp_acc_diff', 'diff_acc_diff']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db60aff2-cf3f-4fcf-9e81-454dca97efbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "masses = runs_topk['diff_acc'].apply(lambda s: s < 0).groupby(level=['dataset', 'model', 'k']).sum()\n",
    "shapes = runs_topk.groupby(level=['model', 'k']).size()\n",
    "pvals = (masses / shapes).unstack(0)\n",
    "\n",
    "pvals.applymap(lambda pval: 2 * min(pval, 1 - pval) if pval <= 0.5 else pval)  # two-sided"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ddd94d-ecb9-490e-a6eb-24f4cf5d7236",
   "metadata": {},
   "source": [
    "## Within-node similarity pre-post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a983a0c-c602-4f18-bbe4-0e2a0dbe227f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = runs_node_recovery \\\n",
    "    .reset_index() \\\n",
    "    .groupby(['dataset', 'model']) \\\n",
    "    [['trained_sim_avg', 'comp_sim_avg', 'diff_sim_avg']] \\\n",
    "    .mean() \\\n",
    "    .rename({k : k + '_resample' for k in ['trained_sim_avg', 'comp_sim_avg', 'diff_sim_avg']}, axis=1)\n",
    "\n",
    "tmp = tmp.merge(exact_node_recovery, how='inner', left_index=True, right_index=True)\n",
    "\n",
    "tmp['trained_sim_avg_diff'] = tmp['trained_sim_avg'] - tmp['trained_sim_avg_resample']\n",
    "tmp['comp_sim_avg_diff'] = tmp['comp_sim_avg'] - tmp['comp_sim_avg_resample']\n",
    "tmp['diff_sim_avg_diff'] = tmp['diff_sim_avg'] - tmp['diff_sim_avg_resample']\n",
    "\n",
    "tmp[['trained_sim_avg_diff', 'comp_sim_avg_diff', 'diff_sim_avg_diff']]#.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09b193e-9b08-4441-8d65-37474950ab12",
   "metadata": {},
   "outputs": [],
   "source": [
    "pvals = runs_node_recovery['diff_sim_avg'].apply(lambda s: s < 0).groupby(level=[0, 1]).mean()\n",
    "pvals.apply(lambda pval: 2 * min(pval, 1 - pval) if pval <= 0.5 else pval)  # two-sided"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966da7a7-d3a8-459b-8270-09533e89582b",
   "metadata": {},
   "source": [
    "## Correlation of distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d7f767-87a3-45cd-be01-38408eb6820e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pvals = runs_dist_corr['diff_corr'].apply(lambda s: s < 0).groupby(level=[0, 1]).mean()\n",
    "pvals.apply(lambda pval: 2 * min(pval, 1 - pval) if pval <= 0.5 else pval)  # two-sided"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30b1712-2652-4c93-9879-12a737f3a03a",
   "metadata": {},
   "source": [
    "## Embedding distances vs graph distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155fd024-4fc7-45dc-aacc-d2644152cce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pvals = runs_emb_vs_graph['diff_node_corr'].apply(lambda s: s < 0).groupby(level=[0, 1]).mean()\n",
    "pvals.apply(lambda pval: 2 * min(pval, 1 - pval) if pval <= 0.5 else pval)  # two-sided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364db59f-36c2-4f33-9120-ef3a48be6c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pvals = runs_emb_vs_graph['diff_text_corr'].apply(lambda s: s < 0).groupby(level=[0, 1]).mean()\n",
    "pvals.apply(lambda pval: 2 * min(pval, 1 - pval) if pval <= 0.5 else pval)  # two-sided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fed721-504d-4b0d-91ee-557468a7cacb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
